L2: Sector and disk failures

=== Solution discussion of bad-sector exercise

draw refinement diagram
  RemappedDiskAPI  (the spec, given)
  RemappedDiskImpl (the code)
  BadSectorAPI  (given)
    One bad sector
    Implemented in Haskell
    No proof

What is a disk?
  Show generic disk
    uninterpreted memory (See Upd.v)
    with a domain (See Sized.v)

Abstraction function
  draw picture of spec disk and code disk
    code disk has one more block
  What should be true about the non-bad sectors?
    value should be equal
  What should be true about the bad sector?
    its value is equal to the last disk's sector
  What if the bad sector address is the last address?
    no remapping necessary
  What if the bad sector address is past the end of the disk?
    disallow, and check during initialization

  Explain what's with None vs Some x
    in-bounds vs out-of-bounds
  What happens to the bad sector?
    It's (Some x) for a garbage value x.

Prove read
  symbolic execution results in 6 states :(
    d is real disk
    v0 is bad sector
    s is spec disk
    for each prove abstract function holds
      branch 1: address is the bad sector
       	case 1: valid bad sector read
	case 2: oob out of read
	case 3: read bad sector
      branch 2: address is not a bad sector
        ...
    forward pointer: [prog_spec] and Hoare logic will make this cleaner

Write implementation
  do not allow writing to the last sector
    semantics define OOB writes as noops
    stray OOB write from the file system would modify the remapped sector
  find out what the bad sector is
  if address is the bad sector address, then write last address
  else write address

  no need for explicit OOB check: lines up on its own

Prove write
  symbolic execution results in 3 states

Prove init
  implementation: returns Initialized only if it made the abstraction hold
  can always decide to return InitFailed
  our impl fails when the bad sector is out of bounds
  .. or when disk is zero-sized!

What have we proven now?
  the code only start when the initial state is valid (abstraction holds)
  for each possible code execution, there is a spec step
  [rd] is of type [Interface StatDB.API]
  look at src/Refinement/Interface.v, definition of [Interface], [op_spec], ..

== Code generation

draw diagram of NBD server, Linux kernel as NBD client,
  queues of requests/responses, calling the Coq code,
  bad sector API implementation, ..

src/RemappedDisk/Server.v
src/BadSectorDisk/ExtrBadSectorDisk.v
remap-nbd/src/BadSectorDisk/Ops.hs

generated code:
  remap-nbd/src/RemappedDiskImpl.hs
  remap-nbd/src/Server.hs
  remap-nbd/app/Main.hs: call runServer
  remap-nbd/src/Network/NBD.hs: runServer, calls Server.serverLoop
  remap-nbd/src/Network/ServerOps.hs: getRequestFromQueue, sendResponseOnQueue

=== Replicated disk (no recovery)

diagram: two disks
  failure model: disk can stop working at any point
  disks report failure (read/write will indicate if disk failed)
  at least one disk remains live
  disks do not come back from a failure

Coq formalization of the fault model (TwoDisk)
  src/TwoDisk/TwoDiskAPI.v
  [bg_failure]

Concurrency makes reasoning about execution difficult
  Concurrency: disk failure can happen at any point in the execution
  Two specific problems:
    Creates many forks in the symbolic execution tree
    Makes it difficult to reason about state, because state keeps changing
  two techniques that will help us

technique 1: pre- and post-conditions (predicates)
  [prog_spec]
  like Hoare logic
  also includes a recovery condition that we will talk about tomorrow
    will let us talk about possible ways the system can crash
  helps avoid the 6 cases we saw above in RemappedDisk

  the reason we might be able to avoid considering all these cases is that we
    can write the pre- and post-conditions in a way that captures all cases.

technique 2: a way of writing predicates that combines many executions
  main idea: stable predicates
  stability: not affected by concurrent execution (due to [bg_failure])
  example: how to write the abstraction relations?
    naive plan: first disk live \/ second disk live \/ both are live and equal..
    if you break this up into 3 cases, the "both are live" is not stable
      must consider a "fork" at every point where "both are live" degrades
    better plan: stable facts that remain true regardless of [bg_failure]
    [maybe_holds]: d_0 ?|= eq d_s /\ d_1 ?|= eq d_s

to use these techniques, first re-state the code-level semantics using [prog_spec]
  src/ReplicatedDisk/TwoDiskProgSpec.v
  [maybe_holds]
  [maybe_holds_stable]
  [prog_spec] ghost state: here, typically tuple of disk + frame predicate

src/ReplicatedDisk/ReplicatedDiskImpl.v
  work through implementations of Read, DiskSize, DiskSizeInit, init_at, Init
    what if we didn't initialize?
    of course our abstraction wouldn't hold, but so what?
    could someone observe an incorrect behavior at the spec level?
  walk through the proof of Read_ok
  discuss Write_ok and write_read_ok specs
  walk through the proof of DiskSize_ok: same as Read_ok, basically
  discuss init_at_ok: induction because of fixpoint loop
  walk through the proof of DiskSizeInit_ok
    if we do two [step]s in a row, we get an [exists] subgoal
    automation couldn't figure out how to instantiate the evars for precondition
    reason: it depends on [r], the result of the first [DiskSize] call
    [destruct r] first, now [step] can keep going through

assignment:
  git pull to get some small updates
  implement Write
  prove Write_ok
  prove the sanity-checker: write_read_check_ok
  optionally prove init_at_ok and Init_ok
